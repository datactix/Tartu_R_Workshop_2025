---
title: "Data Wrangling Cookbook"
format: 
  html:
    toc: true
    toc-location: left
    toc_float: true
    code-overflow: scroll
    embed-resources: true
editor: visual
---

## Importance of Data Wrangling in Data Analysis

Data wrangling is a critical step in the data analysis process, transforming raw, messy datasets into clean, structured, and meaningful formats suitable for analysis. It ensures data consistency, accuracy, and reliability, which are essential for generating valid insights. In Life Sciences, this can involve cleaning experimental data, integrating datasets from different sources, and preparing data for visualization or statistical modeling.

### Overview of the Tidyverse Philosophy

The Tidyverse is a collection of R packages guided by the [Tidy Data Principles](https://vita.had.co.nz/papers/tidy-data.pdf):

There are three principles which make a dataset tidy:

1.  Each column contains a single variable

2.  Each row contains a single observation

3.  Each value must have its own cell

    ![](images/tidy-data_principles.png)

This uniform structure simplifies data manipulation and analysis, making workflows intuitive and reproducible. Built on a consistent grammar, Tidyverse tools enable seamless integration of tasks like filtering, transforming, and visualizing data, ensuring clarity and efficiency.

### Key Tidyverse Packages for Data Wrangling (``` readr,``dplyr ```, `tidyr`)

-   **`readr`**: Enables fast and user-friendly import of data from CSV, TSV, and other text formats, with flexible handling of column types and encodings.
-   **`dplyr`**: Focuses on efficient data manipulation, providing intuitive functions for filtering, summarizing, and transforming data.
-   **`tidyr`**: Specializes in reshaping and organizing datasets, allowing users to pivot between long and wide formats or handle missing values.

Together, these packages streamline the process of wrangling data into an analysis-ready format.

## Set-up

```{r}
# load tidyverse libraries
library(tibble)
library(readr)
library(dplyr)
library(tidyr)
# alternatively: library(tidyverse)

# load non-tidyverse libraries
library(writexl)
library(here)
```

------------------------------------------------------------------------

## Load, Generate, and Inspect Data

### Load Data

Recipes on how to import data from different file formats.

-   **Recipe 1a: Reading CSV Files**

    How to import Comma Separated Variable file format.

    ```{r}
    df_data <- readr::read_csv(file = here::here("data/wrangling_files/synthetic_data_2024-11-24.csv"), 
                                      
                    # consider the first row as column names
                    col_names = TRUE, 
                    # ability to skip the N first rows if needed
                    skip = 0,
                    # ability to force variable type, by default it guesses
                    col_types = NULL)

    df_data
    ```

-   **Recipe 1b: Reading TSV Files**

    How to import Tab Separated Variable file format

    ```{r}
    df_data <- readr::read_tsv(file=here::here("data/wrangling_files/synthetic_data_2024-11-24.tsv"), 
                    # consider the first row as column names
                    col_names = TRUE, 
                    # ability to skip the N first rows if needed
                    skip = 0,
                    # ability to force a variable type per column, by default it guesses
                    col_types = NULL)

    df_data

    # see also: readr::read_delim()
    ```

-   **Recipe 1c: Importing Excel Files**

    How to import XLS or XLSX files

    ```{r}
    df_data <- readxl::read_excel(path = here::here("data/wrangling_files/synthetic_data_2024-11-24.xlsx"), 
                       # specify name or index of the sheet to read
                       sheet = "sheet_2",
                       # consider the first row for column names
                       col_names = TRUE, 
                       # ability to skip the N first rows if needed
                       skip = 0,
                       # ability to force a variable type per column, by default it guesses
                       col_types = NULL)

    df_data
    ```

### Generate a Synthetic Dataset

Generating Synthetic data is a valuable tool for learning and practicing tidy data analysis. It allows users to work with realistic, controlled datasets without concerns about confidentiality or access restrictions. Synthetic data is especially helpful for demonstrating workflows, testing methods, and debugging code in a reproducible manner.

**Recipe 2: generate synthetic data**

An example on how to use R to generate synthetic dataset with different sampling strategies.

```{r}
# set a random seed to promote reproducibility
# it is required as we use random generators
set.seed(42)

nb_subjects = 25
synthetic_data <- tibble::tibble(Subject_Id = paste0("SUBJ", 1:nb_subjects),
                                 # variable from a uniform distribution
                                 Age = runif(n = nb_subjects, min = 20, max = 80),
                                 # variable sample from define categories and probabilities
                                 Sex = sample(x = c("Male", "Female", NA), prob = c(0.3, 0.5, 0.2), 
                                              size = nb_subjects, replace = TRUE),
                                 # variable from a normal distribution where standard deviation 
                                 # depends on a continuous variable
                                 Biomarker_1 = rnorm(n = nb_subjects, 
                                                     mean = 150, 
                                                     sd = 10*Age*0.05),
                                 # variable from a normal distribution where the mean 
                                 # conditionnaly depends on a categorical variable
                                 Biomarker_2 = rnorm(n = nb_subjects, 
                                                     mean = dplyr::case_when(
                                                       Sex == "Female" ~ 60,
                                                       Sex == "Male" ~ 40,
                                                       .default = NA), 
                                                     sd = 10))
synthetic_data

# see also: ?Distributions for more examples of available distributions
```

### **Inspecting Data**

Recipes to have a look at your data, and to check that the import went well. Always check that all your expected variables and observations are present, as well as the data type of each variable.

-   **Recipe 3a: Quick pick (only a few rows)**

    Output the first few rows of your dataset;

    ```{r}
    # looking at the top 5 rows
    head(synthetic_data, n = 5)
    # see also: tail()
    ```

-   **Recipe 3b: View Dataset Structure**

    Check the full data structure (variable names, data type, number of observations).

    ```{r}
    # provide the full list of variable with type, and sample values
    dplyr::glimpse(synthetic_data)
    ```

-   **Recipe 3c: View Dataset inside RStudio**

    Use RStudio IDE to have a full look at the data table.

    ```{r}
    # opens a tabular view of the dataset in RStudio
    # View(synthetic_data)
    ```

------------------------------------------------------------------------

## Preparing Data

### Selecting, Renaming and Reordering Columns

-   **Recipe 4a: Selecting Columns**

    Define the specific columns of your data you want to keep

    ```{r}
    # use variable names to select them
    synthetic_data_mini <- synthetic_data |> 
                            dplyr::select(Subject_Id, Age, Sex)
    synthetic_data_mini
    ```

-   **Recipe 4b: Reordering Columns**

    Re-order the columns within your data.frame

    ```{r}
    # swap column order according to list of variables provided
    synthetic_data |> 
      dplyr::select(Subject_Id, Sex, Age, Biomarker_2, Biomarker_1)

    # see also: dplyr::relocate()
    ```

-   **Recipe 4c: Renaming Columns**

    Rename the column names of your data.frame

    ```{r}
    # rename column names
    synthetic_data |> 
      dplyr::rename(DonorId = Subject_Id, 
                    Age_VO = Age)
    ```

### Reformatting Data Types

-   **Recipe 5a: Converting Character Column to Factor**

    Converting a character column into a factor provides the ability to control the order of the different levels. It is important for visualization (e.g. order the bar plot categories) and for analysis (e.g. which level will be considered baseline)

    ```{r}
    # convert column to factor
    synthetic_data |>
      dplyr::mutate(Sex = factor(Sex, levels = c("Male", "Female")))
    ```

-   **Recipe 5b: Convert Character Column to Numeric**

    Convert a character column to numeric. Be careful that all characters are properly recognized as numeric, otherwise they will be replaced by NA values.

    ```{r}
    # convert character column to numeric
    tibble(weight = c("55.1", "47.2", "63"),
           height = c("156", "188.2", "176.5")) |> 
      dplyr::mutate(across(where(is.character), as.numeric))
    ```

-   **Recipe 5c: \[Advanced\] Handling Dates and Times**

    Due to the diversity of Date and Time formats, there is a full dedicated package to handle them. Check the tidyverse **lubridate** package for more info.

    ```{r}
    # check R package lubridate for dates and times
    # most versatile function is parse_date_time()
    x <- c("2009-01-01", "02022010", "02-02-2010")
    lubridate::parse_date_time(x, c("dmY", "ymd"))

    #see documentation: ?lubridate::parse_date_time
    ```

------------------------------------------------------------------------

## Selecting Observations

### Ordering Rows

-   **Recipe 6a:** Arranging rows according to specific columns

    re-order your data.frame according to one or many columns. Use function desc() to reverse the order.

    ```{r}
    synthetic_data |> 
      # order by Sex categories, and decreasing Age
      dplyr::arrange(Sex, desc(Age))
    ```

### Filtering Rows

Recipes to filter-out rows, or observations, in your data.frame.

-   **Recipe 6b: Subsetting Data by Conditions**

    select rows by using a logical criteria defined with the variables contained in the data.frame.

    ```{r}
    synthetic_data |> 
      # look for rows where Age < 30 AND Sex is Female
      dplyr::filter(Age < 30, Sex == "Female")
    ```

-   **Recipe 6b: Removing missing data**

    Filter-out rows where a given column is not NA

    ```{r}
    synthetic_data |> 
      # look for rows where Sex is NOT NA
      dplyr::filter(!is.na(Sex))
    ```

See more advanced operations at [row-wise operation from Posit](https://dplyr.tidyverse.org/articles/rowwise.html)

### Selecting Columns

Recipes to keep only certain columns by different criteria.

-   **Recipe 7a:Selecting Columns by Name or Pattern**

    ```{r}
    # select subject_id column, and any column names containing string "Biomarker"
    synthetic_data |> 
      dplyr::select(Subject_Id, tidyselect::contains("Biomarker"))

    # see also: tidyselect::start_with(), ends_with(), matches()
    ```

-   **Recipe 7b: Drop Columns by Name**

    ```{r}
    # remove Age and Sex columns by using the minus symbol
    synthetic_data |> 
      dplyr::select(-Age, -Sex)
    ```

See more advanced case at [Colwise operations from Posit](https://dplyr.tidyverse.org/articles/colwise.html)

### Creating and Transforming Variables

Recipes to create new variable from scratch, or to derive new variables from existing ones.

-   **Recipe 8a: Adding New Variables**

    Compute a new variable based on existing ones

    ```{r}
    # create a new variable based on existing ones
    synthetic_data |> dplyr::mutate(Biomarker_Ratio = Biomarker_2/Biomarker_1)
    ```

-   **Recipe 8b: Normalizing and Scaling Variables**

scale a numerical variable by substrating its mean value, and by dividing it by the standard deviation (creating a z-score)

```{r}
synthetic_data |> 
  dplyr::mutate(Biomarker1_zscore = scale(Biomarker_1, center = TRUE, scale=TRUE))
```

-   **Recipe 8c: Modifying a character variable with StringR package**

```{r}
# replace the prefix from a character variable
synthetic_data |> 
  dplyr::mutate(Subject_Id = stringr::str_replace(Subject_Id, 
                pattern = "SUBJ",
                replacement = "Donor_"))

# See ?stringr for more string manipulation options
# https://stringr.tidyverse.org
```

-   **Recipe 8d: Applying a Function to Many Variables**

    Specify multiple columns with the across() to apply at once chosen function. It allows to overwrite the variables or to name them by adding a prefix or suffix.

    ```{r}
    # apply the log transformation across all columns with Biomarker in their name
    synthetic_data |> 
      dplyr::mutate(across(contains("Biomarker"), 
                           # function to apply. '~' is used to specify a function
                           ~ log(.x), 
                           # name transformed columns according to col name + "_log"
                           # if not specified, it overwrites the variables
                           .names = "{.col}_log"))
    ```

### Handling Missing Data

-   **Recipe 9a: Detecting Missing Values**

    Identify all rows where there is at least one missing value.

    ```{r}
    synthetic_data |>  
      # identify any rows where there is a NA value
      dplyr::filter(dplyr::if_any(everything(), ~ is.na(.x)))

    # see also:  filter(if_all(everything(), ~ !is.na(.x)))
    ```

-   **Recipe 9b: Removing Rows with Missing Data**

    Getting rid of row where at least a missing value has been identified.

    ```{r}
    # drop rows with any missing value
    synthetic_data |> tidyr::drop_na()

    # see also, drop_na(Subject_Id, Sex) to drop only if Subject_Id et Sex have missing values
    ```

-   **Recipe 9c: Removing Cols with Missing Data**

    Drop all columns as soon as they contain one missing value.

    ```{r}
    synthetic_data |>
      # select all columns where there is no missing data
      select(where(~ !any(is.na(.))))

    #see also: select(where(~ !all(is.na(.)))) 
    ```

------------------------------------------------------------------------

## Summarizing and Aggregating Data

### Summarizing Variables

-   **Recipe 10a: Descriptive Statistics (Mean, Median, etc.)**

```{r}
synthetic_data |> summarise(Age_Mean = mean(Age, na.rm = TRUE),
                            Age_Median = median(Age, na.rm = TRUE),
                            Biomarker_1_sd = sd(Biomarker_1, na.rm = TRUE))

# Note: more useful in the context of group_by operations
```

-   **Recipe 10b: Summarize across many variables**

```{r}
synthetic_data |>
  # compute overall summaries
  dplyr::summarise(
    # on columns that are of type numeric, compute median value
    across(where(is.numeric), ~median(.x, na.rm = TRUE), .names = "median_{.col}"))
```

### Grouped Operations

-   **Recipe 11b: Summarizing Within Groups**

    ```{r}
    synthetic_data |>
      # compute by group according to Sex variable.
      dplyr::group_by(Sex) |>
      # compute overall summaries
      dplyr::summarise(
        # on columns that are of type numeric, compute median value
        across(where(is.numeric), ~median(.x, na.rm = TRUE), .names = "median_{.col}"),
        # on specific columns, compute min value
        across(c(Age, Biomarker_1), ~min(.x, na.rm = TRUE), .names = "min_{.col}"))
    ```

------------------------------------------------------------------------

## Reshaping Data

### Pivoting Data

Pivoting data is a crucial skill for transforming datasets between **wide** and **long** formats, enabling more effective analysis and visualization. In its **wide format**, data is often easier to read but less suitable for computational tasks. Pivoting to a **long format** structures the data for tidy principles, where each row represents a single observation, making it compatible with functions for summarization, modeling, and plotting (e.g., `ggplot2`). Conversely, pivoting back to a **wide format** is essential for generating summary tables or reports. Mastering data pivoting ensures flexibility in handling datasets and streamlines workflows across diverse analytical tasks.

![](images/pivot_table.png){fig-align="center" width="500"}

-   **Recipe 12a: Wide-to-Long Transformations**

    ```{r}
    # define table with wide format
    df_measurements <- tibble::tibble(id = 1:10,
                                      wk1 = rnorm(n = 10, mean = 10),
                                      wk2 = rnorm(n = 10, mean = 12),
                                      wk3 = rnorm(n = 10, mean = 15))

    df_measurements_long <- df_measurements |>
      # transform to long format by collapsing the columns starting with "wk"
      pivot_longer(
        cols = starts_with("wk"),
        names_to = "week",
        #names_prefix = "wk",
        values_to = "measurements",
        values_drop_na = TRUE
      )
    head(df_measurements_long)
    ```

-   **Recipe 12b: Long-to-Wide Transformations**

    ```{r}
    # inverse transformation from long to wide
    df_measurements_long %>%
      pivot_wider(names_from = week, values_from = measurements) |>
      head()
    ```

------------------------------------------------------------------------

## Combining and Merging Data

### Merging Datasets

To merge two data frames in R based on specific ID columns, you can use the dplyr package. Here are four ways to join the data frames, ensuring observations are matched correctly regardless of their order:

1.  **left_join()**: Combines data frames by keeping all rows from the left data frame and matching rows from the right. All rows from the left are included in the final result.

2.  **right_join()**: Keeps all rows from the right data frame and includes matching rows from the left. This is the opposite of left_join().

3.  **inner_join()**: Retains only the rows with matching IDs in both data frames, excluding any rows that do not match.

4.  **full_join()**: Includes all rows from both data frames, filling in missing values with NA where there are no matches between the ID column.

    ![](images/merge_operations.png){width="300"}

-   **Recipe 14a: Different Types of Joins (Inner, Outer, Left, Right)**

    ```{r}
    # create table to merge with similar subject identifier (but different column name)
    df_data <- tibble(DonorId = paste0("SUBJ", 5:10),
                      Biomarker_3 = rnorm(n = 6, mean = 24, sd = 4))
    # Left join to keep all the records from synthetic data, and add new data when matching on Subject_Id
    df_merge <- synthetic_data |> dplyr::left_join(df_data, by = c("Subject_Id" = "DonorId"))
    head(df_merge, n=11)
    # see also: right_join(), inner_join(), outer_join()
    ```

### Combining Rows

-   **Recipe 15a: Appending Rows from a Different Datasets**

    ```{r}
    df_data <- tibble(Subject_Id = paste0("SUBJ", 100:103),
                      Age = 25,
                      Sex = "Male")
    new_data <-synthetic_data |> 
                # binding rows only works on table with same column names
                dplyr::select(Subject_Id, Age, Sex) |>
                # add 'df_data' rows at the bottom of synthetic_data
                dplyr::bind_rows(df_data)
    tail(new_data)
    ```

-   **Recipe 15b: Removing Duplicate Rows**

    ```{r}
    synthetic_data |> 
      dplyr::distinct()

    # see also distinct(Subject_Id, Sex)
    ```

------------------------------------------------------------------------

## Exporting and Saving Data

-   **Recipe 16a:Writing Data as CSV Format**

    ```{r}
    readr::write_csv(x = synthetic_data, 
                     col_names = TRUE, 
                     file = here::here(paste0("data/wrangling_files/synthetic_data_", Sys.Date(),".csv")))
    ```

-   **Recipe 16b: Exporting Data as TSV Format**

    ```{r}
    readr::write_tsv(x = synthetic_data, 
                     col_names = TRUE, 
                     file = here::here(paste0("data/wrangling_files/synthetic_data_", Sys.Date(),".tsv")))
    # see also: readr::write_delim(x, file, delim = "\t")
    ```

-   **Recipe 16c: Exporting to Excel Files**

    ```{r}
    writexl::write_xlsx(x = list(sheet_1 = iris,
                                 sheet_2 = synthetic_data), 
                        col_names = TRUE, 
                        path = here::here(paste0("data/wrangling_files/synthetic_data_", Sys.Date(),".xlsx")))
    ```

-   **\[Advanced\] Recipe 16d:Saving and Loading R Objects**

    ```{r}
    # Save an R object as a compact binary format
    saveRDS(synthetic_data, file = here::here(paste0("data/wrangling_files/synthetic_data_", Sys.Date(),".rds")))

    # read R object from .rds file and assign it to a variable name
    df_data <- readRDS(file = here::here(paste0("data/wrangling_files/synthetic_data_2024-11-24.rds")))
    df_data
    ```

## Continue learning with:

-   [Tidyverse cookbook](https://rstudio-education.github.io/tidyverse-cookbook/)

-   [Cheat Sheets on Tidyverse Packages](https://rstudio.github.io/cheatsheets/)

-   [R For Data Science, free online book.](https://r4ds.hadley.nz/)

-   [R Cookbook](https://rc2e.com/)
